{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pathlib\n",
    "#import cv2\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "from collections import Counter\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from IPython.display import Audio\n",
    "#tensorflow\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "seed_number = 24\n",
    "tf.random.set_seed(seed_number)\n",
    "np.random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"d:/datasets/sound/\"\n",
    "input_dir = os.path.join(root,\"data/\")\n",
    "train_dir = os.path.join(input_dir, 'Training_Data/')\n",
    "val_dir = os.path.join(input_dir, 'val/')\n",
    "test_dir = os.path.join(input_dir, 'Testing_Data/')\n",
    "train_img_dir = os.path.join(root, 'img_data/')\n",
    "val_img_dir = os.path.join(root, 'img_data_val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = [dir for dir in sorted(os.listdir(input_dir)) if os.path.isdir(os.path.join(input_dir, dir))]\n",
    "label_name = [subdir for subdir in sorted(os.listdir(train_dir)) if os.path.isdir(os.path.join(train_dir, subdir))]\n",
    "\n",
    "# информация о папках\n",
    "print(f\"Main directories\\t: {os.listdir(root)}\")\n",
    "print(f\"Dataset sub-directories\\t: {dataset_dir}\")\n",
    "print(f\"Train set directory\\t: {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONST\n",
    "SAMPLE_RATE = 16000 # Sampling rate\n",
    "#duration = 5\n",
    "#hop_length = 512\n",
    "FMIN = 20\n",
    "FMAX = SAMPLE_RATE // 2\n",
    "#n_mels = 128\n",
    "N_FFT = 512\n",
    "Fs = 16000 \n",
    "#samples =SAMPLE_RATE * duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Цикл, который перебирает wav файлы и сохраняет их как спектограммы \n",
    "def wav_to_mel(name_classes):\n",
    "    classes = name_classes.split()\n",
    "    for g in classes:\n",
    "        pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "        for filename in os.listdir(input_dir + f'Training_Data/{g}'):\n",
    "            wav_file_name = input_dir + f'Training_Data/{g}/{filename}'\n",
    "            y, sr = librosa.load(wav_file_name, mono=True, duration=5)\n",
    "            print(y.shape)\n",
    "            plt.specgram(y, NFFT=N_FFT, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "            plt.axis('off');\n",
    "            plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "            plt.clf()\n",
    "    return(print('Done'))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_to_mel('human spoof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбираем 0,3 данных от всего trainig set для validation set\n",
    "def val_make (source, dest):\n",
    "    files = os.listdir(source)\n",
    "    for f in files:\n",
    "        if np.random.rand(1) < 0.3:\n",
    "            shutil.move(source + '/'+ f, dest + '/'+ f)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_make(train_img_dir + \"spoof\", val_img_dir + \"spoof\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_make(train_img_dir + \"human\", val_img_dir + \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем генераторы\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 20,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.15,\n",
    "                                   zoom_range = 0.15,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"nearest\")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#характиристики датасета\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "flow_from_directory = 224\n",
    "img_height = 432\n",
    "img_width = 288\n",
    "#подготавливаем данные\n",
    "train_gen = train_datagen.flow_from_directory(train_img_dir,\n",
    "                                              batch_size = train_batch_size,\n",
    "                                              class_mode = 'binary',\n",
    "                                              target_size = (img_height, img_width),\n",
    "                                              seed = seed_number)\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(val_img_dir,\n",
    "                                          batch_size = val_batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          target_size = (img_height, img_width),\n",
    "                                          seed = seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set batch shape\t: (32, 432, 288, 3)\n"
     ]
    }
   ],
   "source": [
    "#узнаем размерность\n",
    "print(f'Train set batch shape\\t: {next(train_gen)[0].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#строим модель\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((3, 3),  padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu',  activity_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#константы. кол-во эпох обучения и рэйт обучения\n",
    "num_epochs = 15\n",
    "learning_rate = 5e-5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 286, 430, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 96, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 144, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 94, 142, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 14, 128)        73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 296,065\n",
      "Trainable params: 295,233\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#создаем оптимизатор и компилируем модель\n",
    "shape = [img_width, img_height, 3]\n",
    "optimiser = tensorflow.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    \n",
    "model = build_model(shape)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3.84402247626429, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "#веса классов\n",
    "counter = Counter(train_gen.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#планировщик обучения\n",
    "plateau_scheduler = ReduceLROnPlateau(factor=0.2, patience=3, verbose=1, \n",
    "                                      min_delta= 0.005, min_lr=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#это не нужно.  останавливает обучение, когда точность не растет в теч 3 эпох от макисмальной\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc', \n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    mode='auto',\n",
    "    verbose=1,\n",
    "    baseline=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "train_length = len(train_gen.classes)\n",
    "print(train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запускаем\n",
    "history = model.fit(train_gen,\n",
    "                    epochs = num_epochs,\n",
    "                    steps_per_epoch = train_length // train_batch_size,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = 1,\n",
    "                    callbacks = [plateau_scheduler],\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "history_df.to_csv(os.path.join(save_dir, \"history_06_11.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-04b0ed1c9a9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#выводит графики для наглядности\n",
    "train_accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(train_accuracy))\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# точность\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "\n",
    "# потери\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#переводит тестовый набор данных в спектограммы\n",
    "classes = ['test']\n",
    "for g in classes:\n",
    "    pathlib.Path(f'img_data_test/{g}').mkdir(parents=True, exist_ok=True)\n",
    "    for filename in os.listdir(input_dir + f'Testing_Data/{g}'):\n",
    "        wav_file_name = input_dir + f'Testing_Data/{g}/{filename}'\n",
    "        y, sr = librosa.load(wav_file_name, mono=True, duration=5)\n",
    "        print(y.shape)\n",
    "        plt.specgram(y, NFFT=n_fft, Fs=2, Fc=0, noverlap=128, cmap='plasma', sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data_test/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model_sound') #загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) #загружаем генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подготавилваем\n",
    "test_gen = test_datagen.flow_from_directory(root,\n",
    "                                              batch_size = 1,\n",
    "                                              class_mode = None,\n",
    "                                              classes=['img_data_test'],\n",
    "                                              target_size = (img_width, img_height),\n",
    "                                              seed = seed_number,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = new_model.predict(test_gen,verbose=1,steps=len(test_gen)) #делаем предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(prediction,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"file\":filenames,\"pred\":prediction[:,0]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"output.xlsx\")#сохраняем в формате excel "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
